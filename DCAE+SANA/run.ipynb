{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from diffusers import AutoencoderDC\n",
    "dc_vae = AutoencoderDC.from_pretrained(r\"G:\\code\\model\\dc-ae-f32c32-sana-1.1-diffusers\",\n",
    "                                         torch_dtype=torch.float16).to('cuda')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SANA1.1中使用的DC-AEf32c32参数为312M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 统计参数\n",
    "total_params = sum(p.numel() for p in dc_vae.parameters())\n",
    "print(f'{total_params:,} total parameters.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import AutoencoderKL\n",
    "import torch\n",
    "xl_vae = AutoencoderKL.from_pretrained(\"g:code/model/stable-diffusion-xl-base-1.0\", \n",
    "                                      subfolder=\"vae\",\n",
    "                                      torch_dtype=torch.float16).to('cuda')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sdxl的VAE(0.9 version)83M参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_params = sum(p.numel() for p in xl_vae.parameters())\n",
    "print(f'{total_params:,} total parameters.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SDXL-VAE结构 ===\n",
      "SDXL-VAE: encoder\n",
      "SDXL-VAE: decoder\n",
      "SDXL-VAE: quant_conv\n",
      "SDXL-VAE: post_quant_conv\n",
      "--------------------------------------------------\n",
      "=== DC-AE结构 ===\n",
      "整体结构:\n",
      "DC-AE: encoder\n",
      "DC-AE: decoder\n",
      "--------------------------------------------------\n",
      "编码器结构:\n",
      "DC-AE Encoder: conv_in\n",
      "DC-AE Encoder: down_blocks\n",
      "DC-AE Encoder: conv_out\n",
      "--------------------------------------------------\n",
      "解码器结构:\n",
      "DC-AE Decoder: conv_in\n",
      "DC-AE Decoder: up_blocks\n",
      "DC-AE Decoder: norm_out\n",
      "DC-AE Decoder: conv_act\n",
      "DC-AE Decoder: conv_out\n"
     ]
    }
   ],
   "source": [
    "# 比较SDXL-VAE和DC-AE的结构差异\n",
    "print(\"=== SDXL-VAE结构 ===\")\n",
    "for name, child in xl_vae.named_children():\n",
    "    print(f\"SDXL-VAE: {name}\")\n",
    "print('-'*50)\n",
    "\n",
    "print(\"=== DC-AE结构 ===\")\n",
    "print(\"整体结构:\")\n",
    "for name, child in dc_vae.named_children():\n",
    "    print(f\"DC-AE: {name}\")\n",
    "print('-'*50)\n",
    "\n",
    "print(\"编码器结构:\")\n",
    "for name, child in dc_vae.encoder.named_children():\n",
    "    print(f\"DC-AE Encoder: {name}\")\n",
    "print('-'*50)\n",
    "\n",
    "print(\"解码器结构:\")\n",
    "for name, child in dc_vae.decoder.named_children():\n",
    "    print(f\"DC-AE Decoder: {name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **SDXL-VAE**\n",
    "    - SDXL-VAE.encoder\n",
    "        - conv_in\n",
    "        - down_blocks\n",
    "        - mid_block\n",
    "        - conv_norm_out\n",
    "        - conv_act\n",
    "        - conv_out\n",
    "    - SDXL-VAE.decoder\n",
    "        - conv_in\n",
    "        - up_blocks\n",
    "        - mid_block\n",
    "        - conv_norm_out\n",
    "        - conv_act\n",
    "        - conv_out\n",
    "    - SDXL-VAE.quant_conv:Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1))\n",
    "    - SDXL-VAE.post_quant_conv:Conv2d(4, 4, kernel_size=(1, 1), stride=(1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **DC-AE f32c32**\n",
    "    - DC-AE Encoder\n",
    "        - conv_in\n",
    "        - down_blocks\n",
    "            - 0-2:ResBlock*2+DCdownBlock\n",
    "            - 3-4:EfficientViTBlock*3+DCDownBlock\n",
    "            - 5:EfficientViTBlock*3\n",
    "        - conv_out\n",
    "    - DC-AE Decoder\n",
    "        - conv_in\n",
    "        - up_blocks\n",
    "            - 0-2:DCUpBlock2d+ResBLock*2\n",
    "            - 3-4:DCUpBlock2d+EfficientViTBLock*3\n",
    "            - 5:EfficientViTBlock*3\n",
    "        - norm_out:RMSNorm()\n",
    "        - conv_act:ReLu()\n",
    "        - conv_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EfficientViTBlock(\n",
       "  (attn): SanaMultiscaleLinearAttention(\n",
       "    (to_q): Linear(in_features=512, out_features=512, bias=False)\n",
       "    (to_k): Linear(in_features=512, out_features=512, bias=False)\n",
       "    (to_v): Linear(in_features=512, out_features=512, bias=False)\n",
       "    (to_qkv_multiscale): ModuleList(\n",
       "      (0): SanaMultiscaleAttentionProjection(\n",
       "        (proj_in): Conv2d(1536, 1536, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1536, bias=False)\n",
       "        (proj_out): Conv2d(1536, 1536, kernel_size=(1, 1), stride=(1, 1), groups=48, bias=False)\n",
       "      )\n",
       "    )\n",
       "    (nonlinearity): ReLU()\n",
       "    (to_out): Linear(in_features=1024, out_features=512, bias=False)\n",
       "    (norm_out): RMSNorm()\n",
       "  )\n",
       "  (conv_out): GLUMBConv(\n",
       "    (nonlinearity): SiLU()\n",
       "    (conv_inverted): Conv2d(512, 4096, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (conv_depth): Conv2d(4096, 4096, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=4096)\n",
       "    (conv_point): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (norm): RMSNorm()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dc_vae.encoder.down_blocks[3][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    An Autoencoder model introduced in [DCAE](https://arxiv.org/abs/2410.10733) and used in\n",
      "    [SANA](https://arxiv.org/abs/2410.10629).\n",
      "\n",
      "    This model inherits from [`ModelMixin`]. Check the superclass documentation for it's generic methods implemented\n",
      "    for all models (such as downloading or saving).\n",
      "\n",
      "    Args:\n",
      "        in_channels (`int`, defaults to `3`):\n",
      "            The number of input channels in samples.\n",
      "        latent_channels (`int`, defaults to `32`):\n",
      "            The number of channels in the latent space representation.\n",
      "        encoder_block_types (`Union[str, Tuple[str]]`, defaults to `\"ResBlock\"`):\n",
      "            The type(s) of block to use in the encoder.\n",
      "        decoder_block_types (`Union[str, Tuple[str]]`, defaults to `\"ResBlock\"`):\n",
      "            The type(s) of block to use in the decoder.\n",
      "        encoder_block_out_channels (`Tuple[int, ...]`, defaults to `(128, 256, 512, 512, 1024, 1024)`):\n",
      "            The number of output channels for each block in the encoder.\n",
      "        decoder_block_out_channels (`Tuple[int, ...]`, defaults to `(128, 256, 512, 512, 1024, 1024)`):\n",
      "            The number of output channels for each block in the decoder.\n",
      "        encoder_layers_per_block (`Tuple[int]`, defaults to `(2, 2, 2, 3, 3, 3)`):\n",
      "            The number of layers per block in the encoder.\n",
      "        decoder_layers_per_block (`Tuple[int]`, defaults to `(3, 3, 3, 3, 3, 3)`):\n",
      "            The number of layers per block in the decoder.\n",
      "        encoder_qkv_multiscales (`Tuple[Tuple[int, ...], ...]`, defaults to `((), (), (), (5,), (5,), (5,))`):\n",
      "            Multi-scale configurations for the encoder's QKV (query-key-value) transformations.\n",
      "        decoder_qkv_multiscales (`Tuple[Tuple[int, ...], ...]`, defaults to `((), (), (), (5,), (5,), (5,))`):\n",
      "            Multi-scale configurations for the decoder's QKV (query-key-value) transformations.\n",
      "        upsample_block_type (`str`, defaults to `\"pixel_shuffle\"`):\n",
      "            The type of block to use for upsampling in the decoder.\n",
      "        downsample_block_type (`str`, defaults to `\"pixel_unshuffle\"`):\n",
      "            The type of block to use for downsampling in the encoder.\n",
      "        decoder_norm_types (`Union[str, Tuple[str]]`, defaults to `\"rms_norm\"`):\n",
      "            The normalization type(s) to use in the decoder.\n",
      "        decoder_act_fns (`Union[str, Tuple[str]]`, defaults to `\"silu\"`):\n",
      "            The activation function(s) to use in the decoder.\n",
      "        scaling_factor (`float`, defaults to `1.0`):\n",
      "            The multiplicative inverse of the root mean square of the latent features. This is used to scale the latent\n",
      "            space to have unit variance when training the diffusion model. The latents are scaled with the formula `z =\n",
      "            z * scaling_factor` before being passed to the diffusion model. When decoding, the latents are scaled back\n",
      "            to the original scale with the formula: `z = 1 / scaling_factor * z`.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "from diffusers import AutoencoderDC\n",
    "# 我想要查看AutoencoderDC的适配模型\n",
    "# 尝试查看类本身的文档字符串，看是否有相关信息\n",
    "print(AutoencoderDC.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "heavy_daily",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
